# Docker Notes

- [Docker Docs](https://docs.docker.com/get-started/)
- [Docker FAQ](https://docs.docker.com/engine/faq/)
- [Introduction to Docker (GCP)](https://www.cloudskillsboost.google/focuses/1029?parent=catalog)


- note: A lot of the stuff here is copied from other sites

## [What is Docker - Overview ](https://docs.docker.com/get-started/overview/)
- Docker is an open platform for developing, shipping, and running applications 
- Docker enables you to separate your applications from your infrastructure so you can deliver software quickly. 
- With Docker, you can manage your infrastructure in the same ways you manage your applications. 
- By taking advantage of Docker’s methodologies for shipping, testing, and deploying code quickly, you can significantly reduce the delay between writing code and running it in production.

## The Docker Platform
- Docker provides the ability to package and run an application in a loosely isolated environment called a **container**. 
- The isolation and security allows you to run many containers simultaneously on a given host
- Containers are lightweight and contain everything needed to run the application, so you do not need to rely on what is currently installed on the host. 
- You can easily share containers while you work, and be sure that everyone you share with gets the same container that works in the same way.

## What are Containers
- Simply put, a container is **a sandboxed process on your machine that is isolated from all other processes on the host machine**. 
- That isolation leverages kernel namespaces and cgroups, features that have been in Linux for a long time. 
- Docker has worked to make these capabilities approachable and easy to use. 
- To summarize, a container:
    - is a runnable instance of an image. You can create, start, stop, move, or delete a container using the DockerAPI or CLI.
    - can be run on local machines, virtual machines or deployed to the cloud.
    - is portable (can be run on any OS).
    - is isolated from other containers and runs its own software, binaries, and configurations.


## What is a container image?
- When running a container, **it uses an isolated filesystem** 
	- [FILE SYSTEM:](https://www.baeldung.com/linux/rootfs) describes our data, provides a structural way to store/access files from system storage 
- This custom filesystem running in a container is provided by a container image, so the image must contain everything needed to run an application - all dependencies, configurations, scripts, binaries, etc. 
- The image also contains other configuration for the container, such as environment variables, a default command to run, and other metadata.
- so: my application --> Build Docker Image of the application --> Run Docker Image --> Docker Container running (basically the application)


## EXAMPLE:
- checkout github repo 
- site w/ react frontend and django backend 
- Dockerfiles added to both directories
	- Dockerfiles are instructions on how to build the container image
- Docker-compose file (docker-compose.yaml) to build the container images using the dockerfiles from both directories and run them 
	- run ```docker-compose build``` to build the docker images of the frontend and backend apps, and then run ```docker-compose up``` to start running them.
	- run ```docker-compose down``` to stop the containers from running! - doesn't just stop when you exit the terminal THIS IS IMPORTANT 


## [Docker volumes](https://www.youtube.com/watch?v=wZbPmb4soTI)
- preferred mechanism for persisting data generated by and used by docker container
- volumes are just a folder location, designated where data can be stored permanently for use by one or more containers
- 'data' in the container example: 
	- database container: data from db can be saved in the volume
	- w/o volume, if we stopped running our db container, the data stored in the virtual filesystem of the container would be destroyed as well. 
	- containers are created by running images. images are static, can not be changed and edited from the container.
	- data must be saved in a stateful way - program keeps track of the state/interaction - use a volume!
- volume is stored on the host so it can be used again when the container is spun up again 
- Volumes can be added w/ docker client commands or just added in the docker-compose.yaml file 
- volumes are mounted at runtime / run the container
- [use cases](https://docs.docker.com/storage/#good-use-cases-for-volumes):
	- When you need to back up, restore, or migrate data from one Docker host to another, volumes are a better choice. You can stop containers using the volume, then back up the volume’s directory
	- When you want to store your container’s data on a remote host or a cloud provider, rather than locally.
- volumes for react container?
	- [one tutorial stated](https://dev.to/karanpratapsingh/dockerize-your-react-app-4j2e), "Here we'll also mount our code in a volume so that we can sync our changes with the container while developing."
	- changes to code DO show up when interacting with docker containers w/ docker exec -it command but they don't show up on the site... ?
- volume for django container 
	- ["Copy changes made to the project to your image in real-time."](https://adamtheautomator.com/django-docker/)


## [Difference between Containers and VM](https://stackoverflow.com/questions/16047306/how-is-docker-different-from-a-virtual-machine)
- Answer 1 snippet : 
	- A full virtualized system gets its own set of resources allocated to it, and does minimal sharing. You get more isolation, but it is much heavier (requires more resources). 
	- With Docker you get less isolation, but the containers are lightweight (require fewer resources). So you could easily run thousands of containers on a host, and it won't even blink. Try doing that with Xen, and unless you have a really big host, I don't think it is possible
- Answer 2 snippet : 
	- The net effect is that virtualization allows you to run two completely different OSes on the same hardware. 
	- Each guest OS goes through all the processes of bootstrapping, loading kernel, etc. You can have very tight security. For example, a guest OS can't get full access to the host OS or other guests and mess things up.
	- The limitations of containers vs VMs should be obvious now: You can't run completely different OSes in containers like in VMs. However you can run different distros of Linux because they do share the same kernel. 
	- The isolation level is not as strong as in a VM. In fact, there was a way for a "guest" container to take over the host in early implementations. 
	- Also you can see that when you load a new container, an entire new copy of the OS doesn't start like it does in a VM. All containers share the same kernel. This is why containers are light weight. 
	- Also unlike a VM, you don't have to pre-allocate a significant chunk of memory to containers because we are not running a new copy of the OS. This enables running thousands of containers on one OS while sandboxing them, which might not be possible if we were running separate copies of the OS in their own VMs.


- [Distinction between OS and distribution](https://stackoverflow.com/questions/16047306/how-is-docker-different-from-a-virtual-machine) (Linked from FAQ of Docker Doc Site)
	- Debian, Fedora, Red Hat Enterprise, and Ubuntu are all Linux distributions. They are also operating systems.
	- Linux is, technically speaking, just a kernel, which is the core internals of an operating system. The rest of the operating system—the boot code, the GUI, filesystem utilities, etc—are all separate. 
	- Thus, early in Linux's history, folks would gather up the source code to the components of a complete Linux system, build them, set them up to their liking, and distribute them to their friends over the Internet. Hence the term "distribution." 
	- Thus all Linux distributions are also operating systems. If talking about Linux, the two terms are interchangeable. In my opinion, the term "distribution" is antiquated. 
	- While, say, Ubuntu is both a distribution and an OS, I call it only the latter. The term "distribution" is particular to Linux. Thus Mac OS X 10.8 is an OS but not a distribution. Summary: In Linux, the term "distribution" arose due to the manner in which Linux systems were assembled and distributed over the Internet. When talking about a specific Linux system, the terms "distribution" and "operating system" are interchangeable. Non-Linux systems don't use "distribution."


## Limitation of Docker Containers
- LINUX ONLY ? :
	- Docker containers uses linux kernel features like namespaces and cgroups so it can only run on Linux.
	- ALSO you can't have completely different OSes running in the containers, they can only be different distributions, of Linux 
	- [Can Docker Containers run on any OS?](https://sloopstash.com/blog/can-docker-containers-run-on-any-operating-system.html)
		- No, Docker containers can't run on all operating systems directly, and there are reasons behind that. Let me explain in detail why Docker containers won't run on all operating systems:
		- Docker container engine was powered by the core Linux container library (LXC) during the initial releases. After some time, Docker replaced LXC and started to use Containerd, which is another container library which opened simple API to create and manage containers. Now, with Containerd in place, Docker doesn't need to do the heavy lifting with container features of Linux kernel.
		- The factor which powers the container technology is the Linux kernel. Here, the Docker container engine is entirely dependant on the container features of the Linux kernel, and that's the reason why Docker containers cannot run on Windows and Mac operating systems. The Unix kernel powers the Mac operating system, similarly the Windows kernel powers the Windows operating system.
		- In Mac and Windows operating systems, Docker has managed to provision containers on a micro Linux virtual machine. Many people don't know this fact, and so they believe Docker can run on all operating systems.

- BUT w/ Docker Desktop, it will spin up a VM w/ Linux FOR YOU 
- Docker containers are based on linux kernel features so you can only run them on Linux systems AND you can have different linux distributions running in containers since they share the same kernel BUT for macOS and windows users we can simply use docker desktop which spins up a Linux VM
